{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBNjhoX4nwnOSwarOzyrKe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanyamChaudhary27/ML_models_from_scratch/blob/main/Lasso_ElasticNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cY_r9BkV6edn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LASSO:\n",
        "    def __init__(self, n_iterations = 100, learning_rate = 0.1, lam = 0.1):\n",
        "        self.n_iterations = n_iterations\n",
        "        self.learning_rate = learning_rate\n",
        "        self.lam = lam\n",
        "        self.intercept = 0\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y.to_numpy().flatten()\n",
        "        n_samples, n_features = self.X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.intercept = 0\n",
        "\n",
        "        # Batch gradient Descent with L1 (Lasso) regularization\n",
        "        for _ in range(self.n_iterations):\n",
        "            y_pred = self.predict(self.X)\n",
        "            error = y_pred - self.y\n",
        "            dw_data = (1/n_samples) * np.dot(self.X.T, error)\n",
        "            dw_l1 = self.lam * np.sign(self.weights)\n",
        "            self.weights -= self.learning_rate * (dw_data + dw_l1)\n",
        "            db = (1/n_samples) * np.sum(error)\n",
        "            self.intercept -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.weights is None or self.intercept is None:\n",
        "            raise RuntimeError(\"Model has not been fitted yet. Call .fit(X, y) first.\")\n",
        "        return np.dot(X, self.weights) + self.intercept"
      ],
      "metadata": {
        "id": "SeY3EHcK6n8D"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a2edafa"
      },
      "source": [
        "class ElasticNet:\n",
        "    def __init__(self, n_iterations=100, learning_rate=0.1, lam=0.1, alpha=0.5):\n",
        "        # lam is the overall regularization strength\n",
        "        # alpha is the mixing parameter between L1 and L2 (0 for Ridge, 1 for Lasso)\n",
        "        self.n_iterations = n_iterations\n",
        "        self.learning_rate = learning_rate\n",
        "        self.lam = lam\n",
        "        self.alpha = alpha\n",
        "        self.intercept = 0\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y.to_numpy().flatten()\n",
        "        n_samples, n_features = self.X.shape\n",
        "\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.intercept = 0\n",
        "\n",
        "        for _ in range(self.n_iterations):\n",
        "            y_pred = np.dot(self.X, self.weights) + self.intercept\n",
        "            error = y_pred - self.y\n",
        "            dw_data = (1/n_samples) * np.dot(self.X.T, error)\n",
        "            dw_l1 = self.lam * self.alpha * np.sign(self.weights)\n",
        "            dw_l2 = self.lam * (1 - self.alpha) * 2 * self.weights\n",
        "            self.weights -= self.learning_rate * (dw_data + dw_l1 + dw_l2)\n",
        "            db = (1/n_samples) * np.sum(error)\n",
        "            self.intercept -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.weights is None or self.intercept is None:\n",
        "            raise RuntimeError(\"Model has not been fitted yet. Call .fit(X, y) first.\")\n",
        "        return np.dot(X, self.weights) + self.intercept"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ],
      "metadata": {
        "id": "5rYgIKxP9tA_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_california_housing()"
      ],
      "metadata": {
        "id": "MsYgPQZ5-4Sk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(data.data)\n",
        "X.columns = data.feature_names\n",
        "y = pd.DataFrame(data.target)\n",
        "y.columns = data.target_names"
      ],
      "metadata": {
        "id": "MaxpgiQ9_DjX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state =42)"
      ],
      "metadata": {
        "id": "CnT7O1NR_eGk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "Scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "Qeo1oBHE_p4n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = Scaler.fit_transform(X_train)\n",
        "X_val = Scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "G27zY1A8_xS3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_model = LASSO(n_iterations=1000, learning_rate=0.01)\n",
        "elastic_model = ElasticNet(n_iterations=1000, learning_rate=0.01)"
      ],
      "metadata": {
        "id": "SQtA1NXrAAmh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_model.fit(X_train, y_train)\n",
        "elastic_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "n5TH8c38AZ1Q"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_preds = lasso_model.predict(X_val)\n",
        "elastic_preds = elastic_model.predict(X_val)"
      ],
      "metadata": {
        "id": "NfNlFLjhCIJ6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "0cm5-RSVCXqJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y, y_preds):\n",
        "    return mean_squared_error(y, y_preds)"
      ],
      "metadata": {
        "id": "dJ86ojqPCe8C"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rmse(y_val, lasso_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIRlzGxsCoXn",
        "outputId": "fae55d0a-1830-442a-ac9e-ae2c2296703b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6794924441633325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rmse(y_val, elastic_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7gCwpPnCwgU",
        "outputId": "dd807d73-146b-47de-a51f-96d8583ddf92"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6524712990482402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92fe9fce"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "This notebook implemented custom LASSO and ElasticNet regression models from scratch and evaluated their performance on the California Housing dataset. Both models were trained on the preprocessed training data and evaluated on the validation set using Root Mean Squared Error (RMSE).\n",
        "\n",
        "**Performance Summary:**\n",
        "*   **LASSO Model RMSE:** 0.679\n",
        "*   **ElasticNet Model RMSE:** 0.652\n",
        "\n",
        "ElasticNet achieved a slightly lower RMSE (0.652) compared to LASSO (0.679) on the validation set, indicating slightly better predictive accuracy for this dataset. This suggests that the combination of L1 and L2 regularization in ElasticNet was marginally more effective than pure L1 regularization (LASSO) for this specific problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27054e29"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Custom LASSO and ElasticNet regression models were implemented and evaluated on the California Housing dataset.\n",
        "*   The Root Mean Squared Error (RMSE) for the LASSO model was 0.679.\n",
        "*   The Root Mean Squared Error (RMSE) for the ElasticNet model was 0.652.\n",
        "*   ElasticNet achieved a slightly lower RMSE (0.652) compared to LASSO (0.679), indicating marginally better predictive accuracy for this dataset.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The results suggest that combining L1 and L2 regularization (ElasticNet) was slightly more effective than pure L1 regularization (LASSO) for this specific regression problem.\n",
        "*   Further hyperparameter tuning for both models could potentially lead to even better performance, or exploring other regularization techniques might offer additional improvements.\n"
      ]
    }
  ]
}